{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0ADFfODOy-2"
      },
      "source": [
        "!git clone https://github.com/giaanthunder/lstm_prediction\n",
        "%cd lstm_prediction\n",
        "\n",
        "!pip install tensorflow\n",
        "!pip install scikit-learn\n",
        "!pip install matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C59DPaogQgjy"
      },
      "source": [
        "import json\n",
        "import os, sys, math, time\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)\n",
        "\n",
        "import numpy as np\n",
        "import plotly.offline as py\n",
        "import plotly.graph_objs as go\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.externals import joblib\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from technical_analysis.generate_labels import Genlabels\n",
        "from technical_analysis.macd import Macd\n",
        "from technical_analysis.rsi import StochRsi\n",
        "from technical_analysis.poly_interpolation import PolyInter\n",
        "from technical_analysis.dpo import Dpo\n",
        "from technical_analysis.coppock import Coppock\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def mean_n_past(data, n): # include current\n",
        "    l = data.shape[0]\n",
        "    result = []\n",
        "    for i in range(l):\n",
        "        p1 = 0 if i<n else (i-n+1)\n",
        "        p2 = i + 1\n",
        "        m = np.mean(data[p1:p2])\n",
        "        result.append(m)\n",
        "    result = np.array(result)\n",
        "    result = np.reshape(result, [l,1])\n",
        "    return result\n",
        "\n",
        "def mean_hull(data, n):\n",
        "    hull = mean_n_past( mean_n_past(data,n//2)*2 - mean_n_past(data,n) , int(math.sqrt(n)) )\n",
        "    return hull\n",
        "\n",
        "\n",
        "\n",
        "def extract_data(data):\n",
        "    # obtain labels\n",
        "    labels = Genlabels(data, window=25, polyorder=3).labels\n",
        "\n",
        "    # obtain features\n",
        "    macd = Macd(data, 6, 12, 3).values\n",
        "    stoch_rsi = StochRsi(data, period=14).hist_values\n",
        "    dpo = Dpo(data, period=4).values\n",
        "    cop = Coppock(data, wma_pd=10, roc_long=6, roc_short=3).values\n",
        "    inter_slope = PolyInter(data, progress_bar=True).values\n",
        "\n",
        "    macd        = macd[30:-1]\n",
        "    stoch_rsi   = stoch_rsi[30:-1]\n",
        "    inter_slope = inter_slope[30:-1]\n",
        "    dpo         = dpo[30:-1]\n",
        "    cop         = cop[30:-1]\n",
        "    labels      = labels[31:]\n",
        "\n",
        "    # truncate bad values and shift label\n",
        "    X = np.array([macd, stoch_rsi, inter_slope, dpo, cop])\n",
        "    X = np.transpose(X)\n",
        "\n",
        "    data = data[30:-1]\n",
        "\n",
        "    return X, labels, data\n",
        "\n",
        "def adjust_data(X, y, split=0.8):\n",
        "    # count the number of each label\n",
        "    count_1 = np.count_nonzero(y)\n",
        "    count_0 = y.shape[0] - count_1\n",
        "    cut = min(count_0, count_1)\n",
        "\n",
        "    # save some data for testing\n",
        "    train_idx = int(cut * split)\n",
        "    \n",
        "    # shuffle data\n",
        "    np.random.seed(42)\n",
        "    shuffle_index = np.random.permutation(X.shape[0])\n",
        "    X, y = X[shuffle_index], y[shuffle_index]\n",
        "\n",
        "    # find indexes of each label\n",
        "    idx_1 = np.argwhere(y == 1).flatten()\n",
        "    idx_0 = np.argwhere(y == 0).flatten()\n",
        "\n",
        "    # grab specified cut of each label put them together \n",
        "    X_train = np.concatenate((X[idx_1[:train_idx]]   , X[idx_0[:train_idx]])   , axis=0)\n",
        "    X_test  = np.concatenate((X[idx_1[train_idx:cut]], X[idx_0[train_idx:cut]]), axis=0)\n",
        "    y_train = np.concatenate((y[idx_1[:train_idx]]   , y[idx_0[:train_idx]])   , axis=0)\n",
        "    y_test  = np.concatenate((y[idx_1[train_idx:cut]], y[idx_0[train_idx:cut]]), axis=0)\n",
        "\n",
        "    # shuffle again to mix labels\n",
        "    np.random.seed(7)\n",
        "    shuffle_train = np.random.permutation(X_train.shape[0])\n",
        "    shuffle_test  = np.random.permutation(X_test.shape[0])\n",
        "\n",
        "    X_train, y_train = X_train[shuffle_train], y_train[shuffle_train]\n",
        "    X_test , y_test  = X_test[shuffle_test]  , y_test[shuffle_test]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def shape_data(X, y, data, timesteps=10):\n",
        "    # scale data\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    # if not os.path.exists('models'):\n",
        "    #     os.mkdir('models')\n",
        "\n",
        "    # joblib.dump(scaler, 'models/scaler.dump')\n",
        "\n",
        "    # reshape data with timesteps\n",
        "    reshaped = []\n",
        "    for i in range(timesteps, X.shape[0] + 1):\n",
        "        reshaped.append(X[i - timesteps:i])\n",
        "    \n",
        "    # account for data lost in reshaping\n",
        "    X = np.array(reshaped)\n",
        "    y = y[timesteps - 1:]\n",
        "    data = data[timesteps-1:]\n",
        "\n",
        "    return X, y, data\n",
        "\n",
        "def build_model():\n",
        "    # first layer\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(32, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # second layer\n",
        "    model.add(LSTM(32, return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # fourth layer and output\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # compile layers\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "hist_dir = 'price_history/'\n",
        "hist_paths = []\n",
        "for path in os.listdir(hist_dir):\n",
        "    hist_paths.append(hist_dir+path)\n",
        "hist_paths.sort()\n",
        "\n",
        "\n",
        "c_lst = []\n",
        "for path in hist_paths:\n",
        "    with open(path) as file:\n",
        "        data = json.load(file)\n",
        "    c_lst += data['c']\n",
        "\n",
        "\n",
        "# load and reshape data\n",
        "X, y, data = extract_data(np.array(c_lst))\n",
        "X, y, data = shape_data(X, y, data, timesteps=10)\n",
        "\n",
        "\n",
        "p = 180\n",
        "X_test = X[-p:]\n",
        "y_test = y[-p:]\n",
        "data_test = data[-p:] \n",
        "\n",
        "# ensure equal number of labels, shuffle, and split\n",
        "X_train, X_val, y_train, y_val = adjust_data(X[:-p], y[:-p])\n",
        "\n",
        "# binary encode for softmax function\n",
        "y_train = to_categorical(y_train, 2)\n",
        "y_val   = to_categorical(y_val, 2)\n",
        "# y_test  = to_categorical(y_test, 2)\n",
        "\n",
        "X_train = tf.convert_to_tensor(X_train)\n",
        "y_train = tf.convert_to_tensor(y_train)\n",
        "X_val   = tf.convert_to_tensor(X_val  )\n",
        "y_val   = tf.convert_to_tensor(y_val  )\n",
        "X_test  = tf.convert_to_tensor(X_test )\n",
        "y_test  = tf.convert_to_tensor(y_test )\n",
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val  .shape)\n",
        "print(y_val  .shape)\n",
        "print(X_test .shape)\n",
        "print(y_test .shape)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdXvOGz-SAlY"
      },
      "source": [
        "print('Training phase')\n",
        "# build and train model\n",
        "model = build_model()\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=8, shuffle=True, validation_data=(X_val, y_val))\n",
        "model.save('lstm_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLSgUDI8SFyj"
      },
      "source": [
        "print('Testing phase')\n",
        "min_model = tf.keras.models.load_model(\"lstm_model\")\n",
        "\n",
        "y_pred = []\n",
        "annos  = []\n",
        "cnt = 0\n",
        "for i in range(X_test.shape[0]):\n",
        "    y = min_model(X_test[i:i+1])[0].numpy()\n",
        "    label = np.argmax(y)\n",
        "    y_pred.append(label)\n",
        "    # score = '%.2f'%(y[label])\n",
        "    # annos.append(score)\n",
        "    # y_true = str(y_test[i].numpy())\n",
        "    # annos.append(y_true)\n",
        "    if y_test[i] == 1:\n",
        "        annos.append(\"U\")\n",
        "    else:\n",
        "        annos.append(\"D\")\n",
        "    if y_test[i] == label:\n",
        "        cnt += 1\n",
        "\n",
        "acc = cnt/y_test.shape[0]\n",
        "print('Test accuracy: %d%%'%(int(acc*100)))\n",
        "\n",
        "hull20 = mean_hull(data_test,20)\n",
        "plt.plot(hull20,color='darkviolet')\n",
        "plt.plot(data_test,color='b')\n",
        "for i in range(len(y_pred)):\n",
        "    if y_pred[i] == 1:\n",
        "        color = 'g'\n",
        "    else:\n",
        "        color = 'r'\n",
        "    plt.plot(i,hull20[i],color=color, marker='.')\n",
        "    # plt.annotate(annos[i], (i,data_test[i],), xytext=(0,5), \n",
        "    #     textcoords=\"offset points\", ha='center')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}